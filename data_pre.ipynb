{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f227607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "Y=np.load('Test_dis.npy')\n",
    "node=np.load('Test_Node.npy')\n",
    "para=np.load('beam_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ed63547",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_exp_np = np.repeat(\n",
    "    para[:, np.newaxis, :],      # 从 (500,2) -> (500,1,2)\n",
    "    repeats=node.shape[1],       # 在第二个轴(231)上重复\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bba522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (500, 231, 4)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate([node, beam_exp_np], axis=-1)\n",
    "print(\"X.shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "538c56ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape: (500, 231, 20)\n"
     ]
    }
   ],
   "source": [
    "Y=Y.reshape(Y.shape[0], Y.shape[1], -1)\n",
    "# Y=Y[:,20,:]\n",
    "print(\"Y.shape:\", Y.shape)  # (500, 231, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82883a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(X, open(\"X_beam.pkl\", \"wb\"))\n",
    "pickle.dump(Y, open(\"Y_beam_2.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "762ab298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before uniqueness check: (500, 1200, 2)\n",
      "Shape after uniqueness check: (500, 630, 2)\n",
      "[[  0   1]\n",
      " [  0  21]\n",
      " [  0  22]\n",
      " ...\n",
      " [227 228]\n",
      " [228 229]\n",
      " [229 230]]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "def generate_pairs(arr):\n",
    "    # Shape of the input array\n",
    "    batch_size, num_elements, pair_length = arr.shape\n",
    "\n",
    "    # We know we need combinations of 2 from the last dimension\n",
    "    pairs = []\n",
    "    for i in range(batch_size):\n",
    "        for j in range(num_elements):\n",
    "            elements = arr[i, j]\n",
    "            # Generate all unique pairs\n",
    "            pair_list = [list(pair) for pair in combinations(elements, 2)]\n",
    "            pairs.append(pair_list)\n",
    "\n",
    "    # Convert the list of pairs to a numpy array\n",
    "    pairs_array = np.array(pairs)\n",
    "\n",
    "    # Reshape to the desired output format\n",
    "    # Combine second and third dimensions\n",
    "    pairs_array = pairs_array.reshape(batch_size, -1, 2)\n",
    "\n",
    "    return pairs_array\n",
    "\n",
    "def unique_pairs(pairs_array):\n",
    "    unique_pairs_list = []\n",
    "    \n",
    "    for batch in pairs_array:\n",
    "        # Use np.unique to remove duplicates within each batch\n",
    "        # In this case, we are not sorting the pairs\n",
    "        unique_pairs = np.unique(batch, axis=0)\n",
    "        unique_pairs_list.append(unique_pairs)\n",
    "    \n",
    "    # Find the maximum number of unique pairs to pad the batches to the same length\n",
    "    max_length = max(len(batch) for batch in unique_pairs_list)\n",
    "    \n",
    "    # Pad all batches to the same length\n",
    "    padded_batches = []\n",
    "    for batch in unique_pairs_list:\n",
    "        pad_width = max_length - len(batch)\n",
    "        padded_batch = np.pad(batch, ((0, pad_width), (0, 0)), mode='constant')\n",
    "        padded_batches.append(padded_batch)\n",
    "    \n",
    "    # Convert to a numpy array\n",
    "    result = np.array(padded_batches)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "input_array =np.load('Test_edge.npy')\n",
    "output_array = generate_pairs(input_array)\n",
    "unique_output_array = unique_pairs(output_array)\n",
    "\n",
    "print(\"Shape before uniqueness check:\", output_array.shape)  # Shape before uniqueness check\n",
    "print(\"Shape after uniqueness check:\", unique_output_array.shape)   # Shape after uniqueness check\n",
    "\n",
    "print(unique_output_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05fd1cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array = np.ones((500, 630, 1))  # For example, fill it with ones\n",
    "\n",
    "# Concatenate along the third dimension\n",
    "combined_array = np.concatenate((unique_output_array, new_array), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a97fb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the filename to save the array\n",
    "filename = \"new_edge.npy\"\n",
    "\n",
    "# Save the array to a .npy file\n",
    "np.save(filename, combined_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
